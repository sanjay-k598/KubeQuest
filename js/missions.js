window.MISSIONS = [ { id:'01-crashloop', title:'CrashLoop on web after deploy', brief:'Users report 500s. The last rollout introduced a bad image. Get web back to Ready.', state:{ deployments:{ web:{ replicas:3, image:'acme/web:v2-bad', labels:{app:'web'}, probes:{readiness:{path:'/healthz',delay:2,timeout:1}} } }, pods:[ {name:'web-6d9c9b-abc12',owner:'web',status:'CrashLoopBackOff',restarts:3,ready:false}, {name:'web-6d9c9b-def34',owner:'web',status:'CrashLoopBackOff',restarts:4,ready:false}, {name:'web-6d9c9b-ghi56',owner:'web',status:'Running',restarts:0,ready:true}], services:[{name:'web-svc',selector:{app:'web'},endpoints:['10.0.0.21']}], nodes:[{name:'node-a',ready:true},{name:'node-b',ready:true}], hints:['Check logs for a pod','Roll back: kubectl rollout undo deployment/web','or set a good image tag'] }, win:(s)=> s.deployments.web.image==='acme/web:v1' || s._rolledBack===true }, { id:'02-imagepull', title:'ImagePullBackOff on api', brief:'New api tag is wrong. Fix tag or registry secret so pods pull successfully.', state:{ deployments:{ api:{ replicas:2, image:'registry.local/api:typo', labels:{app:'api'} } }, pods:[ {name:'api-7999f7-aaa01',owner:'api',status:'ImagePullBackOff',restarts:0,ready:false}, {name:'api-7999f7-bbb02',owner:'api',status:'ImagePullBackOff',restarts:0,ready:false} ], services:[{name:'api-svc',selector:{app:'api'},endpoints:[] }], nodes:[{name:'node-a',ready:true}], hints:['kubectl describe pod <name> shows Events','Fix tag: kubectl set image deploy/api api=registry.local/api:v1'] }, win:(s)=> s.deployments.api.image==='registry.local/api:v1' }, { id:'03-pending', title:'Pods Pending due to resources', brief:'work pods request too much memory. Adjust requests so scheduler can place them.', state:{ deployments:{ work:{ replicas:2, image:'tools/work:v1', labels:{app:'work'}, resources:{requests:{cpu:1, memory:8192}} } }, pods:[ {name:'work-5f756c-xx1',owner:'work',status:'Pending',reason:'Insufficient memory',ready:false}, {name:'work-5f756c-yy2',owner:'work',status:'Pending',reason:'Insufficient memory',ready:false} ], services:[{name:'work-svc',selector:{app:'work'},endpoints:[] }], nodes:[{name:'node-small',ready:true,allocatable:{cpu:2, memory:4096}}], hints:['kubectl describe pod â€¦ to see reason','Patch requests: kubectl patch deploy/work --type=\'merge\' -p \'{"spec":{"template":{"spec":{"containers":[{"name":"work","resources":{"requests":{"memory":"512Mi"}}}]}}}}\''] }, win:(s)=> (s.pods.filter(p=>p.owner==='work' && p.ready).length>=2) } ];